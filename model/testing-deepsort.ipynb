{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Helmet Mapping + Deepsort\n","\n"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","execution_count":5,"source":["import numpy as np\n","import pandas as pd\n","import itertools\n","import glob\n","import os\n","import cv2\n","from sklearn.metrics import accuracy_score\n","from tqdm.auto import tqdm\n","from multiprocessing import Pool\n","from matplotlib import pyplot as plt\n","from sklearn.cluster import KMeans\n","import random"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:53:23.660712Z","iopub.execute_input":"2021-10-06T05:53:23.661064Z","iopub.status.idle":"2021-10-06T05:53:25.029344Z","shell.execute_reply.started":"2021-10-06T05:53:23.661022Z","shell.execute_reply":"2021-10-06T05:53:25.028617Z"},"trusted":true}},{"cell_type":"code","execution_count":6,"source":["# Lets see the image \n","\n","from PIL import Image, ImageDraw\n","\n","img = Image.open('../input/nfl-health-and-safety-helmet-assignment/images/57503_000116_Endzone_frame443.jpg')\n","\n","img"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:53:25.030737Z","iopub.execute_input":"2021-10-06T05:53:25.031585Z","iopub.status.idle":"2021-10-06T05:53:25.671481Z","shell.execute_reply.started":"2021-10-06T05:53:25.031543Z","shell.execute_reply":"2021-10-06T05:53:25.670260Z"},"trusted":true}},{"cell_type":"code","execution_count":7,"source":["sub_df = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/sample_submission.csv')\n","sub_df"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:53:25.672716Z","iopub.execute_input":"2021-10-06T05:53:25.672953Z","iopub.status.idle":"2021-10-06T05:53:25.709425Z","shell.execute_reply.started":"2021-10-06T05:53:25.672928Z","shell.execute_reply":"2021-10-06T05:53:25.708793Z"},"trusted":true}},{"cell_type":"code","execution_count":8,"source":["# load the file\n","\n","df_image_labels = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/image_labels.csv')\n","df_image_labels.head()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:53:25.710968Z","iopub.execute_input":"2021-10-06T05:53:25.711473Z","iopub.status.idle":"2021-10-06T05:53:26.005280Z","shell.execute_reply.started":"2021-10-06T05:53:25.711441Z","shell.execute_reply":"2021-10-06T05:53:26.004433Z"},"trusted":true}},{"cell_type":"code","execution_count":9,"source":["\n","draw_obj = ImageDraw.Draw(img)\n","\n","draw_obj.rectangle(((1099, 456), (1099 + 16, 456 + 15)), outline=(255, 0, 0))\n","img\n","\n","df = df_image_labels.where(df_image_labels[\"image\"]==\"57503_000116_Endzone_frame443.jpg\").dropna()\n","for _ ,(l, w, t, h) in df[['left', 'width', 'top', 'height']].iterrows():\n","        draw_obj.rectangle(((l, t), (l + w, t + h)), outline=(255, 0, 0), width=2)\n","\n","img"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:53:26.006559Z","iopub.execute_input":"2021-10-06T05:53:26.006827Z","iopub.status.idle":"2021-10-06T05:53:26.772915Z","shell.execute_reply.started":"2021-10-06T05:53:26.006797Z","shell.execute_reply":"2021-10-06T05:53:26.768901Z"},"trusted":true}},{"cell_type":"code","execution_count":10,"source":["\n","from IPython.display import Video\n","\n","Video(\"../input/nfl-health-and-safety-helmet-assignment/train/57583_000082_Endzone.mp4\")\n","\n","#note : if video does not start here just duble click the video in the dataset and enjoy  ( $ _ $ )"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:53:26.774020Z","iopub.execute_input":"2021-10-06T05:53:26.774246Z","iopub.status.idle":"2021-10-06T05:53:26.786094Z","shell.execute_reply.started":"2021-10-06T05:53:26.774215Z","shell.execute_reply":"2021-10-06T05:53:26.785032Z"},"trusted":true}},{"cell_type":"code","execution_count":11,"source":["import pandas as pd \n","\n","df = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/image_labels.csv')\n","df = df.where(df[\"image\"]==\"57503_000116_Endzone_frame443.jpg\").dropna()\n","\n","draw_obj = ImageDraw.Draw(img)\n","\n","for _ ,(l, w, t, h) in df[['left', 'width', 'top', 'height']].iterrows():\n","        draw_obj.rectangle(((l, t), (l + w, t + h)), outline=(255, 0, 0), width=2)\n","\n","img"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:53:26.787577Z","iopub.execute_input":"2021-10-06T05:53:26.787998Z","iopub.status.idle":"2021-10-06T05:53:27.704576Z","shell.execute_reply.started":"2021-10-06T05:53:26.787964Z","shell.execute_reply":"2021-10-06T05:53:27.703955Z"},"trusted":true}},{"cell_type":"code","execution_count":12,"source":["# Install helmet-assignment helper code\n","!pip install ../input/helmet-assignment-helpers/helmet-assignment-main/ > /dev/null 2>&1\n","from helmet_assignment.score import NFLAssignmentScorer, check_submission\n","from helmet_assignment.features import add_track_features"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:53:27.705734Z","iopub.execute_input":"2021-10-06T05:53:27.706136Z","iopub.status.idle":"2021-10-06T05:53:39.163150Z","shell.execute_reply.started":"2021-10-06T05:53:27.706092Z","shell.execute_reply":"2021-10-06T05:53:39.162132Z"},"trusted":true}},{"cell_type":"markdown","source":["# Baseline helmet mapping\n","This section uses the simple helmet mapping approach from the awesome notebook:\n","\n","https://www.kaggle.com/its7171/nfl-baseline-simple-helmet-mapping"],"metadata":{}},{"cell_type":"markdown","source":["## Settings and loading data\n","\n","Note I've extracted `max_iter`, `DIG_STEP` and `DIG_MAX` to the top for easy experimentation. I've also modified the code to run in debug mode if running on the public test set."],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["n_test_videos = len(os.listdir('../input/nfl-health-and-safety-helmet-assignment/test/'))\n","# Run in debug mode unless during submission\n","if n_test_videos == 6:\n","    debug = True\n","else:\n","    debug = False\n","\n","# Configurables\n","n_debug_samples = 1\n","random_state = 42\n","CONF_THRE = 0.4\n","max_iter = 1000\n","DIG_STEP = 3\n","DIG_MAX = DIG_STEP*10\n","\n","# Read in the data.\n","\n","BASE_DIR = '../input/nfl-health-and-safety-helmet-assignment'\n","\n","labels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\n","if debug:\n","    tracking = pd.read_csv(f'{BASE_DIR}/train_player_tracking.csv')\n","    helmets = pd.read_csv(f'{BASE_DIR}/train_baseline_helmets.csv')\n","else:\n","    tracking = pd.read_csv(f'{BASE_DIR}/test_player_tracking.csv')\n","    helmets = pd.read_csv(f'{BASE_DIR}/test_baseline_helmets.csv')\n","    \n","tracking = add_track_features(tracking)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:53:39.164937Z","iopub.execute_input":"2021-10-06T05:53:39.165349Z","iopub.status.idle":"2021-10-06T05:53:45.575295Z","shell.execute_reply.started":"2021-10-06T05:53:39.165304Z","shell.execute_reply":"2021-10-06T05:53:45.574629Z"},"trusted":true}},{"cell_type":"code","execution_count":14,"source":["def add_cols(df):\n","    df['game_play'] = df['video_frame'].str.split('_').str[:2].str.join('_')\n","    if 'video' not in df.columns:\n","        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n","    return df\n","\n","if debug:\n","    helmets = add_cols(helmets)\n","    labels = add_cols(labels)\n","    # Select `n_debug_samples` worth of videos to debug with\n","    sample_videos = labels['video'].drop_duplicates() \\\n","        .sample(n_debug_samples, random_state=random_state).tolist()\n","    sample_gameplays = ['_'.join(x.split('_')[:2]) for x in sample_videos]\n","    tracking = tracking[tracking['game_play'].isin(sample_gameplays)]\n","    helmets = helmets[helmets['video'].isin(sample_videos)]\n","    labels = labels[labels['video'].isin(sample_videos)]\n","tracking.shape, helmets.shape, labels.shape"],"outputs":[],"metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T05:53:45.577640Z","iopub.execute_input":"2021-10-06T05:53:45.577996Z","iopub.status.idle":"2021-10-06T05:53:59.364786Z","shell.execute_reply.started":"2021-10-06T05:53:45.577968Z","shell.execute_reply":"2021-10-06T05:53:59.364218Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["def find_nearest(array, value):\n","    value = int(value)\n","    array = np.asarray(array).astype(int)\n","    idx = (np.abs(array - value)).argmin()\n","    return array[idx]\n","\n","def norm_arr(a):\n","    a = a-a.min()\n","    a = a/a.max()\n","    return a\n","    \n","def dist(a1, a2):\n","    return np.linalg.norm(a1-a2)\n","\n","def dist_for_different_len(a1, a2):\n","    assert len(a1) >= len(a2), f'{len(a1)}, {len(a2)}'\n","    len_diff = len(a1) - len(a2)\n","    a2 = norm_arr(a2)\n","    if len_diff == 0:\n","        a1 = norm_arr(a1)\n","        return dist(a1,a2), ()\n","    else:\n","        min_dist = 10000\n","        min_detete_idx = None\n","        cnt = 0\n","        del_list = list(itertools.combinations(range(len(a1)),len_diff))\n","        if len(del_list) > max_iter:\n","            del_list = random.sample(del_list, max_iter)\n","        for detete_idx in del_list:\n","            this_a1 = np.delete(a1, detete_idx)\n","            this_a1 = norm_arr(this_a1)\n","            this_dist = dist(this_a1, a2)\n","            #print(len(a1), len(a2), this_dist)\n","            if min_dist > this_dist:\n","                min_dist = this_dist\n","                min_detete_idx = detete_idx\n","                \n","        return min_dist, min_detete_idx\n","        \n","def rotate_arr(u, t, deg=True):\n","    if deg == True:\n","        t = np.deg2rad(t)\n","    R = np.array([[np.cos(t), -np.sin(t)],\n","                  [np.sin(t),  np.cos(t)]])\n","    return  np.dot(R, u)\n","\n","def dist_rot(tracking_df, a2):\n","    tracking_df = tracking_df.sort_values('x')\n","    x = tracking_df['x']\n","    y = tracking_df['y']\n","    min_dist = 10000\n","    min_idx = None\n","    min_x = None\n","    for dig in range(-DIG_MAX,DIG_MAX+1,DIG_STEP):\n","        arr = rotate_arr(np.array((x,y)), dig)\n","        this_dist, this_idx = dist_for_different_len(np.sort(arr[0]), a2)\n","        if min_dist > this_dist:\n","            min_dist = this_dist\n","            min_idx = this_idx\n","            min_x = arr[0]\n","    tracking_df['x_rot'] = min_x\n","    player_arr = tracking_df.sort_values('x_rot')['player'].values\n","    players = np.delete(player_arr,min_idx)\n","    return min_dist, players\n","\n","\n","def mapping_df(args):\n","    video_frame, df = args\n","    gameKey,playID,view,frame = video_frame.split('_')\n","    gameKey = int(gameKey)\n","    playID = int(playID)\n","    frame = int(frame)\n","    this_tracking = tracking[(tracking['gameKey']==gameKey) & (tracking['playID']==playID)]\n","    est_frame = find_nearest(this_tracking.est_frame.values, frame)\n","    this_tracking = this_tracking[this_tracking['est_frame']==est_frame]\n","    len_this_tracking = len(this_tracking)\n","    df['center_h_p'] = (df['left']+df['width']/2).astype(int)\n","    df['center_h_m'] = (df['left']+df['width']/2).astype(int)*-1\n","    df = df[df['conf']>CONF_THRE].copy()\n","    if len(df) > len_this_tracking:\n","        df = df.tail(len_this_tracking)\n","    df_p = df.sort_values('center_h_p').copy()\n","    df_m = df.sort_values('center_h_m').copy()\n","    \n","    if view == 'Endzone':\n","        this_tracking['x'], this_tracking['y'] = this_tracking['y'].copy(), this_tracking['x'].copy()\n","    a2_p = df_p['center_h_p'].values\n","    a2_m = df_m['center_h_m'].values\n","\n","    min_dist_p, min_detete_idx_p = dist_rot(this_tracking ,a2_p)\n","    min_dist_m, min_detete_idx_m = dist_rot(this_tracking ,a2_m)\n","    if min_dist_p < min_dist_m:\n","        min_dist = min_dist_p\n","        min_detete_idx = min_detete_idx_p\n","        tgt_df = df_p\n","    else:\n","        min_dist = min_dist_m\n","        min_detete_idx = min_detete_idx_m\n","        tgt_df = df_m\n","    #print(video_frame, len(this_tracking), len(df), len(df[df['conf']>CONF_THRE]), this_tracking['x'].mean(), min_dist_p, min_dist_m, min_dist)\n","    tgt_df['label'] = min_detete_idx\n","    return tgt_df[['video_frame','left','width','top','height','label']]\n","\n","p = Pool(processes=4)\n","submission_df_list = []\n","df_list = list(helmets.groupby('video_frame'))\n","with tqdm(total=len(df_list)) as pbar:\n","    for this_df in p.imap(mapping_df, df_list):\n","        submission_df_list.append(this_df)\n","        pbar.update(1)\n","p.close()\n","\n","submission_df = pd.concat(submission_df_list)\n","submission_df.to_csv('submission-baseline.csv', index=False)"],"outputs":[],"metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-06T05:53:59.365849Z","iopub.execute_input":"2021-10-06T05:53:59.366174Z"},"trusted":true}},{"cell_type":"markdown","source":["## Score the predictions before applying deepsort postprocessing\n","\n","The scores are roughly ~0.3, which is similar to the public leaderboard."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["if debug:\n","    scorer = NFLAssignmentScorer(labels)\n","    baseline_score = scorer.score(submission_df)\n","    print(f\"validation score {baseline_score:0.4f}\")"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# Deepsort Postprocessing\n","\n","Deepsort is a popular framework for object tracking within video. \n","- [This blog post](https://nanonets.com/blog/object-tracking-deepsort/\n",") shows some examples of it being put to use.\n","- This notebook shows how to apply deepsort to this helmet dataset: https://www.kaggle.com/s903124/nfl-helmet-with-yolov5-deepsort-starter\n","- You can also read the paper for deepsort here: https://arxiv.org/pdf/1703.07402.pdf\n","\n","The approach is fairly simple:\n","1. Step through each frame in a video and apply the deepsort algorithm. This clusters helmets across frames when it is the same player/helmet.\n","2. Group by each of these deepsort clusters - and pick the most common label for that cluster. Then override all of the predictions for that helmet to the same player."],"metadata":{}},{"cell_type":"markdown","source":["## Importing Deepsort from dataset\n","Because your submission is not allowed to use internet access, you can reference the deepsort codebase from the attached dataset. Deepsort also has a dependency of `easydict` which I've also added as a dataset."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import sys\n","sys.path.append('../input/easydict-master/easydict-master/')\n","# https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch\n","sys.path.append('../input/yolov5-deepsort-pytorch/Yolov5_DeepSort_Pytorch-master/Yolov5_DeepSort_Pytorch-master/deep_sort_pytorch/')\n","from deep_sort.deep_sort import DeepSort\n","from utils.parser import get_config"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["## Deepsort config\n","\n","Deepsort uses a config yaml file for some settings. These are just the default configs and could be improved."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["%%writefile deepsort.yaml\n","\n","DEEPSORT:\n","  REID_CKPT: \"../input/yolov5-deepsort-pytorch/ckpt.t7\"\n","  MAX_DIST: 0.2\n","  MIN_CONFIDENCE: 0.3\n","  NMS_MAX_OVERLAP: 0.5\n","  MAX_IOU_DISTANCE: 0.9\n","  MAX_AGE: 15\n","  N_INIT: 1\n","  NN_BUDGET: 30\n"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":["\n","\n","def compute_color_for_id(label):\n","    \"\"\"\n","    Simple function that adds fixed color depending on the id\n","    \"\"\"\n","    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n","\n","    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n","    return tuple(color)\n","\n","def plot_one_box(x, im, color=None, label=None, line_thickness=3):\n","    # Plots one bounding box on image 'im' using OpenCV\n","    assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to plot_on_box() input image.'\n","    tl = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n","    color = color or [random.randint(0, 255) for _ in range(3)]\n","    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n","    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n","    if label: \n","        tf = max(tl - 1, 1)  # font thickness\n","        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n","        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n","        cv2.rectangle(im, c1, c2, color, -1, cv2.LINE_AA)  # filled\n","        cv2.putText(im, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n","    return im"],"outputs":[],"metadata":{"_kg_hide-input":true,"trusted":true}},{"cell_type":"markdown","source":["## Functions to apply deepsort to helmet boxes.\n","\n","Below are two functions `deepsort_helmets` which runs deepsort across a video. There is a lot of room for improving this function. The merging of deepsort labels onto the original helmet boxes is currently done in a very crude manner.\n","\n","`add_deepsort_label_col` mapps the most common label to each deepsort cluster."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["def deepsort_helmets(video_data,\n","                     video_dir,\n","                     deepsort_config='deepsort.yaml',\n","                     plot=False,\n","                     plot_frames=[]):\n","    \n","    # Setup Deepsort\n","    cfg = get_config()\n","    cfg.merge_from_file(deepsort_config)    \n","    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n","                        max_dist=cfg.DEEPSORT.MAX_DIST,\n","                        min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n","                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP,\n","                        max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n","                        max_age=cfg.DEEPSORT.MAX_AGE,\n","                        n_init=cfg.DEEPSORT.N_INIT,\n","                        nn_budget=cfg.DEEPSORT.NN_BUDGET,\n","                        use_cuda=True)\n","    \n","    # Run through frames.\n","    video_data = video_data.sort_values('frame').reset_index(drop=True)\n","    video_file = f'{video_dir}/{myvideo}.mp4'\n","    if os.path.exists('/kaggle/working/temp'):\n","        shutil.rmtree('/kaggle/working/temp')\n","    os.mkdir('/kaggle/working/temp')\n","    !ffmpeg \\\n","        -hide_banner \\\n","        -loglevel fatal \\\n","        -nostats \\\n","    ds = []\n","    for frame, d in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):\n","        d['x'] = (d['left'] + round(d['width'] / 2))\n","        d['y'] = (d['top'] + round(d['height'] / 2))\n","\n","        xywhs = d[['x','y','width','height']].values\n","\n","        cap = cv2.VideoCapture(f'{video_dir}/{myvideo}.mp4')\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1) # optional\n","        success, image = cap.read()\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        confs = np.ones([len(d),])\n","        clss =  np.zeros([len(d),])\n","        outputs = deepsort.update(xywhs, confs, clss, image)\n","\n","        if (plot and frame > cfg.DEEPSORT.N_INIT) or (frame in plot_frames):\n","            for j, (output, conf) in enumerate(zip(outputs, confs)): \n","\n","                bboxes = output[0:4]\n","                id = output[4]\n","                cls = output[5]\n","\n","                c = int(cls)  # integer class\n","                label = f'{id}'\n","                color = compute_color_for_id(id)\n","                im = plot_one_box(bboxes, image, label=label, color=color, line_thickness=2)\n","            fig, ax = plt.subplots(figsize=(15, 10))\n","            video_frame = d['video_frame'].values[0]\n","            ax.set_title(f'Deepsort labels: {video_frame}')\n","            plt.imshow(im)\n","            plt.show()\n","\n","        preds_df = pd.DataFrame(outputs, columns=['left','top','right','bottom','deepsort_cluster','class'])\n","        if len(preds_df) > 0:\n","            # TODO Fix this messy merge\n","            d = pd.merge_asof(d.sort_values(['left','top']),\n","                              preds_df[['left','top','deepsort_cluster']] \\\n","                              .sort_values(['left','top']), on='left', suffixes=('','_deepsort'),\n","                              direction='nearest')\n","        ds.append(d)\n","    dout = pd.concat(ds)\n","    return dout\n","\n","def add_deepsort_label_col(out):\n","    # Find the top occuring label for each deepsort_cluster\n","    sortlabel_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n","        .sort_values(ascending=False).to_frame() \\\n","        .rename(columns={'label':'label_count'}) \\\n","        .reset_index() \\\n","        .groupby(['deepsort_cluster']) \\\n","        .first()['label'].to_dict()\n","    # Find the # of times that label appears for the deepsort_cluster.\n","    sortlabelcount_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n","        .sort_values(ascending=False).to_frame() \\\n","        .rename(columns={'label':'label_count'}) \\\n","        .reset_index() \\\n","        .groupby(['deepsort_cluster']) \\\n","        .first()['label_count'].to_dict()\n","    \n","    out['label_deepsort'] = out['deepsort_cluster'].map(sortlabel_map)\n","    out['label_count_deepsort'] = out['deepsort_cluster'].map(sortlabelcount_map)\n","\n","    return out\n","\n","def score_vs_deepsort(myvideo, out, labels):\n","    # Score the base predictions compared to the deepsort postprocessed predictions.\n","    myvideo_mp4 = myvideo + '.mp4'\n","    labels_video = labels.query('video == @myvideo_mp4')\n","    scorer = NFLAssignmentScorer(labels_video)\n","    out_deduped = out.groupby(['video_frame','label']).first().reset_index()\n","    base_video_score = scorer.score(out_deduped)\n","    \n","    out_preds = out.drop('label', axis=1).rename(columns={'label_deepsort':'label'})\n","    print(out_preds.shape)\n","    out_preds = out_preds.groupby(['video_frame','label']).first().reset_index()\n","    print(out_preds.shape)\n","    deepsort_video_score = scorer.score(out_preds)\n","    print(f'{base_video_score:0.5f} before --> {deepsort_video_score:0.5f} deepsort')"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["## Apply Deepsort to Baseline Predictions"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Add video and frame columns to submission.\n","submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_')\n","submission_df['frame'] = submission_df['video_frame'].str.split('_').str[-1].astype('int')\n","\n","if debug:\n","    video_dir = '../input/nfl-health-and-safety-helmet-assignment/train/'\n","else:\n","    video_dir = '../input/nfl-health-and-safety-helmet-assignment/test/'\n","\n","# Loop through test videos and apply. If in debug mode show the score change.\n","out_ds = []\n","outs = []\n","for myvideo, video_data in tqdm(submission_df.groupby('video'), total=submission_df['video'].nunique()):\n","    print(f'==== {myvideo} ====')\n","    if debug:\n","        # Plot deepsort labels when in debug mode.\n","        out = deepsort_helmets(video_data, video_dir, plot_frames=[10, 150, 250])\n","    else:\n","        out = deepsort_helmets(video_data, video_dir)\n","    out_ds.append(out)\n","    out = add_deepsort_label_col(out)\n","    outs.append(out)\n","    if debug:\n","        # Score\n","        score_vs_deepsort(myvideo, out, labels)\n","submission_deepsort = pd.concat(outs).copy()"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# Check Submission & Save\n","Finally we will create a submission file and check that it passes the submission requirements.\n","The steps are:\n","1. Drop the `label` and replace with `label_deepsort` predictions.\n","2. Remove any duplicate labels within a single video/frame. This is required to meet the submission requirements.\n","3. Save the results."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["ss = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/sample_submission.csv')\n","submission_deepsort[\"submission_deepsort\"] = submission_deepsort['label_deepsort'].fillna(ss[\"label_deepsort\"])"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"markdown","source":["# Display video showing predictions\n","\n","Lastly, if we want to review our predictions we can create a video to review the predictions using the `video_with_predictions` function from the `helmet_assignment` helper package."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["from helmet_assignment.video import video_with_predictions\n","from IPython.display import Video, display\n","\n","if debug:\n","    submission_deepsort['video'] = submission_deepsort['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n","    debug_videos = submission_deepsort['video'].unique()\n","    debug_labels = labels.query('video in @debug_videos')\n","    scorer = NFLAssignmentScorer(debug_labels)\n","    scorer.score(submission_deepsort)\n","    `\n","    # Create video showing predictions for one of the videos.\n","    video_out = video_with_predictions(\n","        f'../input/nfl-health-and-safety-helmet-assignment/train/{debug_videos[0]}',\n","        scorer.sub_labels)\n","    \n","    frac = 0.60 # scaling factor for display\n","    display(Video(data=video_out,\n","                  embed=True,\n","                  height=int(720*frac),\n","                  width=int(1280*frac))\n","           )"],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}]}