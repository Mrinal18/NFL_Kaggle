{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Starter"],"metadata":{}},{"cell_type":"markdown","source":["#  What we want ?? ( Problem statement )"],"metadata":{}},{"cell_type":"markdown","source":["#### Understanding the problem is a very important step \n","\n","#### After reading the information given on the competition’s home page, we can easily understand the situation we are dealing with. Also, we can read more on the NFL and its efforts for health and safety from this website: www.NFL.com/PlayerHealthandSafety.\n","\n","\n","#### Here I am trying to put things in a simple manner: \n","\n","#### In a sense we can say that :\n","#### we are given an image and we need to detect some objects(bbox) in the image along with their label. \n"],"metadata":{}},{"cell_type":"markdown","source":["#### Image ( picked the first image in the images folder ) "],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["# Lets see the image \n","\n","from PIL import Image, ImageDraw\n","\n","img = Image.open('../input/nfl-health-and-safety-helmet-assignment/images/57503_000116_Endzone_frame443.jpg')\n","\n","img"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:33.418331Z","iopub.execute_input":"2021-10-06T05:18:33.418810Z","iopub.status.idle":"2021-10-06T05:18:34.005371Z","shell.execute_reply.started":"2021-10-06T05:18:33.418728Z","shell.execute_reply":"2021-10-06T05:18:34.003576Z"},"trusted":true}},{"cell_type":"markdown","source":["#### We can see there are some players playing Football, \n","\n","#### Detect the helmet and make the bounding boxes"],"metadata":{}},{"cell_type":"code","execution_count":20,"source":["import pandas as pd \n","\n","df = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/image_labels.csv')\n","df = df.where(df[\"image\"]==\"57503_000116_Endzone_frame443.jpg\").dropna()\n","\n","draw_obj = ImageDraw.Draw(img)\n","\n","for _ ,(l, w, t, h) in df[['left', 'width', 'top', 'height']].iterrows():\n","        draw_obj.rectangle(((l, t), (l + w, t + h)), outline=(255, 0, 0), width=2)\n","\n","img"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:26:37.266980Z","iopub.execute_input":"2021-10-06T05:26:37.267703Z","iopub.status.idle":"2021-10-06T05:26:38.007424Z","shell.execute_reply.started":"2021-10-06T05:26:37.267656Z","shell.execute_reply":"2021-10-06T05:26:38.006402Z"},"trusted":true}},{"cell_type":"markdown","source":["#### We can see that the helmets are detected properly, Next step is to give the proper label to each helmet \n","\n","#### Every player has one helmet, and the label is the associate player's number.\n"],"metadata":{}},{"cell_type":"markdown","source":["#### So we can rephrase over sentence as :\n","\n","#### We are given an image of players playing in the NFL and we want to detect the helmets in the image and also provide the associate player's number as the label.\n","\n","#### Let’s have a look at the subbmition.csv file "],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["sub_df = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/sample_submission.csv')\n","sub_df"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:34.905292Z","iopub.execute_input":"2021-10-06T05:18:34.905581Z","iopub.status.idle":"2021-10-06T05:18:34.939337Z","shell.execute_reply.started":"2021-10-06T05:18:34.905548Z","shell.execute_reply":"2021-10-06T05:18:34.938621Z"},"trusted":true}},{"cell_type":"markdown","source":["#### Now that we have a basic understanding of the problem statement, And there is a lot in the story that will be covered when we walk through the data files provided to us in the next section, have fun :) "],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["#sub_df.info()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:34.941221Z","iopub.execute_input":"2021-10-06T05:18:34.941998Z","iopub.status.idle":"2021-10-06T05:18:34.946016Z","shell.execute_reply.started":"2021-10-06T05:18:34.941959Z","shell.execute_reply":"2021-10-06T05:18:34.945258Z"},"trusted":true}},{"cell_type":"markdown","source":["# What we have ?? ( Data analysis ) "],"metadata":{}},{"cell_type":"markdown","source":["#### Well there is a lot in the data, but primarily we have folders and CSV files \n","\n","#### lets start with folders \n","\n","* images\n","* train/test\n","\n","#### images folder contains a lot of images from the game ( like the one we saw above ), this folder is given for the training of the helmet detector model.\n","\n","#### train/test folders contain the video files that we have to use while training and inferring the helmet and label detector model."],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["#folders"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:34.947156Z","iopub.execute_input":"2021-10-06T05:18:34.947840Z","iopub.status.idle":"2021-10-06T05:18:34.960427Z","shell.execute_reply.started":"2021-10-06T05:18:34.947795Z","shell.execute_reply":"2021-10-06T05:18:34.959480Z"},"trusted":true}},{"cell_type":"markdown","source":["## Let's have a look at CSV files "],"metadata":{}},{"cell_type":"markdown","source":["### image_labels.csv"],"metadata":{}},{"cell_type":"markdown","source":["#### This file contains the corresponding bbox for helmets in the images from the images folder "],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["# load the file\n","\n","df_image_labels = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/image_labels.csv')\n","df_image_labels.head()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:34.961504Z","iopub.execute_input":"2021-10-06T05:18:34.962120Z","iopub.status.idle":"2021-10-06T05:18:35.139521Z","shell.execute_reply.started":"2021-10-06T05:18:34.962076Z","shell.execute_reply":"2021-10-06T05:18:35.138319Z"},"trusted":true}},{"cell_type":"markdown","source":["#### lets look at one image ( first one from the above table )"],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["img = Image.open('../input/nfl-health-and-safety-helmet-assignment/images/57503_000116_Endzone_frame443.jpg')\n","img"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:35.141012Z","iopub.execute_input":"2021-10-06T05:18:35.141341Z","iopub.status.idle":"2021-10-06T05:18:35.605144Z","shell.execute_reply.started":"2021-10-06T05:18:35.141301Z","shell.execute_reply":"2021-10-06T05:18:35.604533Z"},"trusted":true}},{"cell_type":"markdown","source":["#### lets see what the first data point in the image label.csv says \n","#### we only considering the first row : \n","\n","57503_000116_Endzone_frame443.jpg\tHelmet\t**1099\t16\t456\t15**\n","    "],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["\n","draw_obj = ImageDraw.Draw(img)\n","\n","draw_obj.rectangle(((1099, 456), (1099 + 16, 456 + 15)), outline=(255, 0, 0))\n","img"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:35.606234Z","iopub.execute_input":"2021-10-06T05:18:35.606612Z","iopub.status.idle":"2021-10-06T05:18:36.060681Z","shell.execute_reply.started":"2021-10-06T05:18:35.606575Z","shell.execute_reply":"2021-10-06T05:18:36.059805Z"},"trusted":true}},{"cell_type":"markdown","source":["#### we see there is only one helmet marked \n","\n","#### that means, every row in the image_label.csv represents a single helmet in a single image \n","#### and there are a lot of helmets in the image\n","\n","#### In other words: If there are x helmets in an image then there will be x rows in the image_labels.csv corresponding to the same image \n","\n","\n","#### we can simply iterate over all the rows corresponding to our image and get all the helmets marked "],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["df = df_image_labels.where(df_image_labels[\"image\"]==\"57503_000116_Endzone_frame443.jpg\").dropna()\n","for _ ,(l, w, t, h) in df[['left', 'width', 'top', 'height']].iterrows():\n","        draw_obj.rectangle(((l, t), (l + w, t + h)), outline=(255, 0, 0), width=2)\n","\n","img"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:36.061743Z","iopub.execute_input":"2021-10-06T05:18:36.061965Z","iopub.status.idle":"2021-10-06T05:18:36.684519Z","shell.execute_reply.started":"2021-10-06T05:18:36.061940Z","shell.execute_reply":"2021-10-06T05:18:36.683562Z"},"trusted":true}},{"cell_type":"markdown","source":["#### Now we should be clear about images and image_labels.csv, together we can use them for the training of the helmet detector model"],"metadata":{}},{"cell_type":"markdown","source":["## train_labels.csv"],"metadata":{}},{"cell_type":"markdown","source":["#### before going to the CSV file let’s have one deep look into the train folder, its videos and all.\n"],"metadata":{}},{"cell_type":"markdown","source":["\n","#### For those who have no idea of what this game is...\n","\n","#### Let’s think like this:\n","\n","#### There is pay going on in the closed room. There are two cameras in the room, one is on the front wall ( Endzone view ) and one on the side wall(Sideline) :)\n","\n","#### So obviously there are two videos for each play, one recorded everything from the front and the other recorder everything from the side, But both represent the same play \n"],"metadata":{}},{"cell_type":"markdown","source":["#### let’s have a look at the first video  "],"metadata":{}},{"cell_type":"markdown","source":["#### Endzone"],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["\n","from IPython.display import Video\n","\n","Video(\"../input/nfl-health-and-safety-helmet-assignment/train/57583_000082_Endzone.mp4\")\n","\n","#note : if video does not start here just duble click the video in the dataset and enjoy  ( $ _ $ )"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:36.687573Z","iopub.execute_input":"2021-10-06T05:18:36.688309Z","iopub.status.idle":"2021-10-06T05:18:36.697566Z","shell.execute_reply.started":"2021-10-06T05:18:36.688263Z","shell.execute_reply":"2021-10-06T05:18:36.696693Z"},"trusted":true}},{"cell_type":"markdown","source":["#### Sideline"],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["Video(\"../input/nfl-health-and-safety-helmet-assignment/train/57583_000082_Sideline.mp4\")"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:36.698893Z","iopub.execute_input":"2021-10-06T05:18:36.699267Z","iopub.status.idle":"2021-10-06T05:18:36.709790Z","shell.execute_reply.started":"2021-10-06T05:18:36.699213Z","shell.execute_reply":"2021-10-06T05:18:36.708767Z"},"trusted":true}},{"cell_type":"markdown","source":["#### well that cleared a lot about the videos and all ...\n","\n","#### We know that video is nothing but just a set of frames( images ) running very fast the rate at which frame moves is called as frame rate more formally no. of frames passed in one second is called as frame rate \n","\n","#### Previously in the image_label.csv we saw that there is one image and a lot of helmets and each helmet is represented in one row of CSV file making it large. here we can think of two images ( one from the Endzone video and one from Sideline video ) representing the same situation in the play.\n","\n","\n","#### To simplify \n","\n","#### There is a play \n","\n","#### there are two videos for this pay \n","\n","#### Each video contains a x frames \n","\n","#### Each frame makes y rows in the train_label.csv ( i.e y helmets ) \n"],"metadata":{}},{"cell_type":"markdown","source":["#### Now that we saw what’s there in the train folder we can start understanding train_label.csv "],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["df_train_labels = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/train_labels.csv')\n","df_train_labels.head()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:36.711260Z","iopub.execute_input":"2021-10-06T05:18:36.711525Z","iopub.status.idle":"2021-10-06T05:18:39.268131Z","shell.execute_reply.started":"2021-10-06T05:18:36.711498Z","shell.execute_reply":"2021-10-06T05:18:39.267227Z"},"trusted":true}},{"cell_type":"markdown","source":["\n","#### Let’s go over every column names \n","\n","* Gamekey: name of the game ( formally ID of the game )\n","* playID: name of the play  ( formally play ID)\n","\n","* video: name of the video file (formally same thing *(_)* )\n","\n","#### extra note begins \n","\n","#### let’s take the eg: 57583_000082_Endzone.mp4, here \n","\n","#### string before first '_' represents the gamekey (57583)\n","#### string before second '_' represents the playID (82)\n","#### string after second '_' represents the Category of the video ( either Endzone or Sideline)\n","\n","#### extra note ends \n","            \n","* View: says what camera is used (formally type of the video  either Endzone or Sideline)\n","\n","* video_frame : name of the video frame ( given )\n","* frame : frame number ( helps to know the sequence of the frames)\n","\n","\n","#### Now the column names we have seen so far occur repeatedly in the datafame"],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["# lets look over columns \n","print(df_train_labels.columns)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:39.269272Z","iopub.execute_input":"2021-10-06T05:18:39.269893Z","iopub.status.idle":"2021-10-06T05:18:39.274985Z","shell.execute_reply.started":"2021-10-06T05:18:39.269860Z","shell.execute_reply":"2021-10-06T05:18:39.274168Z"},"trusted":true}},{"cell_type":"markdown","source":["#### remember every frame ( image ) has a lot of helmets and every helmet has to be represented by four values left, width, top, and hight \n","\n","\n","* Label: name of the player wearing a helmet (or its number)\n","* left, width, top, height: defines the exact position of the helmet in the image \n","\n","\n","#### (the following description is the same as given on the competition’s home page )\n","*  impactType: a description of the type of helmet impact: helmet, shoulder, body, ground, etc.\n","* isDefinitiveImpact: True/False indicator of definitive impacts. Definitive impact boxes are given additional weight in the scoring algorithm.\n","* isSidelinePlayer: True/False indicator of if the helmet box is on the sideline of the play. Only rows where this field is False will be used in the scoring.\n","\n","\n","#### And That's all :) \n"],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["#end"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:39.276675Z","iopub.execute_input":"2021-10-06T05:18:39.276979Z","iopub.status.idle":"2021-10-06T05:18:39.288277Z","shell.execute_reply.started":"2021-10-06T05:18:39.276937Z","shell.execute_reply":"2021-10-06T05:18:39.287327Z"},"trusted":true}},{"cell_type":"markdown","source":["## train/test_baseline_helmets.csv\n","\n","\n","#### Let's look at the data"],"metadata":{}},{"cell_type":"code","execution_count":15,"source":["\n","df_train_baseline = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/train_baseline_helmets.csv')\n","\n","df_train_baseline.head()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:39.289679Z","iopub.execute_input":"2021-10-06T05:18:39.289993Z","iopub.status.idle":"2021-10-06T05:18:40.590473Z","shell.execute_reply.started":"2021-10-06T05:18:39.289951Z","shell.execute_reply":"2021-10-06T05:18:40.589495Z"},"trusted":true}},{"cell_type":"markdown","source":["#### in this data We see that there are three categories of columns \n","\n","1. Video_frame: \n"," \tname of the video frame file \n","    \n","2. left, width, top, height: \n","    predicted positions of the helmet in the images \n","    \n","3. conf: \n","    confidence of the model ( how much the model is sure about the position of the helmet in the image )"],"metadata":{}},{"cell_type":"markdown","source":["\n","#### this file contains imperfect baseline predictions for helmet boxes\n","\n","#### well what does it mean by imperfect baseline?\n","\n","* They trained a model on the images in the images folder and gave a baseline to us, in other words, we should try developing the model that at least outperforms this model ( above the baseline )\n","\n"],"metadata":{}},{"cell_type":"code","execution_count":16,"source":["#end"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:40.591628Z","iopub.execute_input":"2021-10-06T05:18:40.591871Z","iopub.status.idle":"2021-10-06T05:18:40.595216Z","shell.execute_reply.started":"2021-10-06T05:18:40.591843Z","shell.execute_reply":"2021-10-06T05:18:40.594703Z"},"trusted":true}},{"cell_type":"markdown","source":["## train/test_player_tracking.csv\n","\n","#### One of the most imp csv files "],"metadata":{}},{"cell_type":"markdown","source":["####  well there is a lot going on here \n","\n","\n","#### All the information that we have seen so far is pretty reasonable and understandable that's why it’s easy to interpret \n","\n","#### Now We have a twist ... \n","\n","#### Each player wears a sensor that helps precisely locate them on the field. And all that information is located in the train_player_tracking.csv\n","\n","#### We knew that the position of the player or pretty much every data given in all other CSV files is important for the development and training  of the machine learning algorithms \n","\n","#### But the real question is how can we use this? \n","\n","* To find that answer let’s look at the data !! \n","\n","\n","\n"],"metadata":{}},{"cell_type":"markdown","source":["#### let's have a look "],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["df_train_player_tracking = pd.read_csv('../input/nfl-health-and-safety-helmet-assignment/train_player_tracking.csv')\n","\n","df_train_player_tracking.head()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:40.596096Z","iopub.execute_input":"2021-10-06T05:18:40.596741Z","iopub.status.idle":"2021-10-06T05:18:41.341234Z","shell.execute_reply.started":"2021-10-06T05:18:40.596708Z","shell.execute_reply":"2021-10-06T05:18:41.340339Z"},"trusted":true}},{"cell_type":"markdown","source":["\n","#### Here we can see that gameKey, playID, and player are known to us, but what are these other things ??\n","\n","#### To find the answer lets hear the complete story \n","\n","#### We know that players are with the sensors but we have to record the reading of those sensors otherwise it’s useless.Well if we are recording the sensor’s response, when should we record it?\n","\n","#### Now let’s look at the time column \n","\n","#### first value : 2018-09-14T00:23:45.500Z\n","\n","#### this time representation is in the ISO 8601 format, in other words, it shows date and time up to millisecond \n","\n","#### date : 2018-09-14  (befour T char in the string )\n","#### time : 00:23:45.500Z (after T char in the string )\n","#### i.e \n","#### 00 - > hr\n","#### 23 - > min \n","#### 45 - > sec \n","#### 500 - > mili sec "],"metadata":{}},{"cell_type":"code","execution_count":18,"source":["# look from 5th to 15th\n","df_train_player_tracking.head(20)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:41.342345Z","iopub.execute_input":"2021-10-06T05:18:41.342575Z","iopub.status.idle":"2021-10-06T05:18:41.375260Z","shell.execute_reply.started":"2021-10-06T05:18:41.342549Z","shell.execute_reply":"2021-10-06T05:18:41.374424Z"},"trusted":true}},{"cell_type":"markdown","source":["#### We can see time difference in the consecutive data points and we will find that for every sec there are 10 recordings in the dataset.\n","#### that is the speed of recording is 10Hz, Which means the sensor data is recorded 10 times pr sec ( very prices )\n","\n","#### Sensor recoreded position, speed , acclaretion ... etc \n","\n","#### Let’s have a quick look at the columns :\n","\n","1. x: player position along the long axis of the field.\n","2. y: player position along the short axis of the field. \n","3. s: speed in yards/second.\n","4. a: acceleration in yards/second^2.\n","5. dis: distance traveled from prior time point, in yards.\n","6. o: orientation of player (deg).\n","7. dir: angle of player motion (deg).\n","8. event: game events like a snap, whistle, etc.\n"],"metadata":{}},{"cell_type":"markdown","source":["#### This all gives different directions we can tackle this particular problem, We should try to find creative ways to use the given data and solve the problem :) "],"metadata":{}},{"cell_type":"markdown","source":["### Thank you, Happy to hear your thoughts/suggestions "],"metadata":{}},{"cell_type":"code","execution_count":19,"source":["#end"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:18:41.376761Z","iopub.execute_input":"2021-10-06T05:18:41.377143Z","iopub.status.idle":"2021-10-06T05:18:41.382909Z","shell.execute_reply.started":"2021-10-06T05:18:41.377056Z","shell.execute_reply":"2021-10-06T05:18:41.382098Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["def deepsort_helmets(video_data,\n","                     video_dir,\n","                     deepsort_config='deepsort.yaml',\n","                     plot=False,\n","                     plot_frames=[]):\n","    \n","    # Setup Deepsort\n","    cfg = get_config()\n","    cfg.merge_from_file(deepsort_config)    \n","    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n","                        max_dist=cfg.DEEPSORT.MAX_DIST,\n","                        min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n","                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP,\n","                        max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n","                        max_age=cfg.DEEPSORT.MAX_AGE,\n","                        n_init=cfg.DEEPSORT.N_INIT,\n","                        nn_budget=cfg.DEEPSORT.NN_BUDGET,\n","                        use_cuda=True)\n","    \n","    # Run through frames.\n","    video_data = video_data.sort_values('frame').reset_index(drop=True)\n","    ds = []\n","    for frame, d in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):\n","        d['x'] = (d['left'] + round(d['width'] / 2))\n","        d['y'] = (d['top'] + round(d['height'] / 2))\n","\n","        xywhs = d[['x','y','width','height']].values\n","\n","        cap = cv2.VideoCapture(f'{video_dir}/{myvideo}.mp4')\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1) # optional\n","        success, image = cap.read()\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        confs = np.ones([len(d),])\n","        clss =  np.zeros([len(d),])\n","        outputs = deepsort.update(xywhs, confs, clss, image)\n","\n","        if (plot and frame > cfg.DEEPSORT.N_INIT) or (frame in plot_frames):\n","            for j, (output, conf) in enumerate(zip(outputs, confs)): \n","\n","                bboxes = output[0:4]\n","                id = output[4]\n","                cls = output[5]\n","\n","                c = int(cls)  # integer class\n","                label = f'{id}'\n","                color = compute_color_for_id(id)\n","                im = plot_one_box(bboxes, image, label=label, color=color, line_thickness=2)\n","            fig, ax = plt.subplots(figsize=(15, 10))\n","            video_frame = d['video_frame'].values[0]\n","            ax.set_title(f'Deepsort labels: {video_frame}')\n","            plt.imshow(im)\n","            plt.show()\n","\n","        preds_df = pd.DataFrame(outputs, columns=['left','top','right','bottom','deepsort_cluster','class'])\n","        if len(preds_df) > 0:\n","            # TODO Fix this messy merge\n","            d = pd.merge_asof(d.sort_values(['left','top']),\n","                              preds_df[['left','top','deepsort_cluster']] \\\n","                              .sort_values(['left','top']), on='left', suffixes=('','_deepsort'),\n","                              direction='nearest')\n","        ds.append(d)\n","    dout = pd.concat(ds)\n","    return dout\n","\n","def add_deepsort_label_col(out):\n","    # Find the top occuring label for each deepsort_cluster\n","    sortlabel_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n","        .sort_values(ascending=False).to_frame() \\\n","        .rename(columns={'label':'label_count'}) \\\n","        .reset_index() \\\n","        .groupby(['deepsort_cluster']) \\\n","        .first()['label'].to_dict()\n","    # Find the # of times that label appears for the deepsort_cluster.\n","    sortlabelcount_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n","        .sort_values(ascending=False).to_frame() \\\n","        .rename(columns={'label':'label_count'}) \\\n","        .reset_index() \\\n","        .groupby(['deepsort_cluster']) \\\n","        .first()['label_count'].to_dict()\n","    \n","    out['label_deepsort'] = out['deepsort_cluster'].map(sortlabel_map)\n","    out['label_count_deepsort'] = out['deepsort_cluster'].map(sortlabelcount_map)\n","\n","    return out\n","\n","def score_vs_deepsort(myvideo, out, labels):\n","    # Score the base predictions compared to the deepsort postprocessed predictions.\n","    myvideo_mp4 = myvideo + '.mp4'\n","    labels_video = labels.query('video == @myvideo_mp4')\n","    scorer = NFLAssignmentScorer(labels_video)\n","    out_deduped = out.groupby(['video_frame','label']).first().reset_index()\n","    base_video_score = scorer.score(out_deduped)\n","    \n","    out_preds = out.drop('label', axis=1).rename(columns={'label_deepsort':'label'})\n","    print(out_preds.shape)\n","    out_preds = out_preds.groupby(['video_frame','label']).first().reset_index()\n","    print(out_preds.shape)\n","    deepsort_video_score = scorer.score(out_preds)\n","    print(f'{base_video_score:0.5f} before --> {deepsort_video_score:0.5f} deepsort')"],"outputs":[],"metadata":{}}]}